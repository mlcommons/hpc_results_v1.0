{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License (MIT)\n",
    "\n",
    "Copyright (c) 2020 NVIDIA CORPORATION. All rights reserved.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters\n",
    "cudadir = \"/usr/common/software/cuda/10.2.89\"\n",
    "homedir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output dirs\n",
    "#datadirs = [\"../scripts/tf_cnn_kernels_nsight/runs/386219\"]\n",
    "#datadirs = [\"../scripts/tf_cnn_kernels_nsight/runs/386058\"]\n",
    "#datadirs = os.path.join(homedir,\"data/tf_2.0b/new_nsight\")\n",
    "datadirs = [\"../data/pytorch_1.5\"]\n",
    "outputdir = \"../results/pytorch_1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_frame(df_metrics):\n",
    "    #Copy the profile frame to make sure not to overwrite it and potentially read it in again if we screwed it up\n",
    "    selectkeys = [\"Precision\", \"Network Name\", \"Batch Size\", \"Pass\", \"Name\"]\n",
    "    \n",
    "    tc_peak_perf_flops = 125*10**12\n",
    "\n",
    "    #as metricdf use df_summary\n",
    "    metricdf = df_metrics.copy()\n",
    "    metricdf.sort_values(by=selectkeys,inplace=True)\n",
    "    metricdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ####### Get timing information\n",
    "\n",
    "    ### CUDA Time\n",
    "    cudatimedf = metricdf[ (metricdf[\"Metric Name\"].str.contains(\"smsp__cycles_elapsed\")) ].sort_values(selectkeys)\n",
    "    # get cycles and rates\n",
    "    cyclesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"total\"), selectkeys+[\"Metric Value\"]]\n",
    "    ratesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"rate\"), selectkeys+[\"Metric Value\"]]\n",
    "    \n",
    "    # combine\n",
    "    cudatimedf = cyclesdf.merge(ratesdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    cudatimedf[\"CUDA Time Avg\"] = cudatimedf[\"Metric Value_x\"] / (cudatimedf[\"Metric Value_y\"] * 1e9)\n",
    "    cudatimedf = cudatimedf.fillna(0.)\n",
    "    # merge into results\n",
    "    metricdf = metricdf.merge(cudatimedf[selectkeys+[\"CUDA Time Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### Tensor Core Time\n",
    "    tctimedf = metricdf[ (metricdf[\"Metric Name\"].str.contains(\"smsp__pipe_tensor_op_hmma_cycles_active\")) ].sort_values(selectkeys)\n",
    "    # get cycles and rates\n",
    "    cyclesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__pipe_tensor_op_hmma_cycles_active\") & (metricdf[\"Metric Type\"]==\"total\"), selectkeys+[\"Metric Value\"]]\n",
    "    ratesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__pipe_tensor_op_hmma_cycles_active\") & (metricdf[\"Metric Type\"]==\"rate\"), selectkeys+[\"Metric Value\"]]\n",
    "    \n",
    "    # combine\n",
    "    tctimedf = cyclesdf.merge(ratesdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    tctimedf[\"TC Time Avg\"] = tctimedf[\"Metric Value_x\"] / (tctimedf[\"Metric Value_y\"] * 1e9).fillna(0.)\n",
    "    tctimedf = tctimedf.fillna(0.)\n",
    "    metricdf = metricdf.merge(tctimedf[selectkeys+[\"TC Time Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### check\n",
    "    #tmpdf = metricdf.loc[(abs(metricdf[\"CUDA Time Avg\"] - metricdf[\"TC Time Avg\"])/metricdf[\"CUDA Time Avg\"] > 0.01) & (metricdf[\"TC Time Avg\"] != 0)]\n",
    "    #if not tmpdf.empty:\n",
    "    #    print(tmpdf)\n",
    "    #    raise ValueError(\"CUDA Time not consistent wit TC Time\")    \n",
    "        \n",
    "        \n",
    "    ####### Get number of FLOPs\n",
    "    \n",
    "    ### FMA FLOPs = number of FMA instructions x 2\n",
    "    metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"fma\"), [\"Metric Value\"]] *= 2\n",
    "    \n",
    "\n",
    "    ### FP64 FLOPs\n",
    "    #metrics = ['smsp__sass_thread_inst_executed_op_dadd_pred_on',\n",
    "    #           'smsp__sass_thread_inst_executed_op_dfma_pred_on',\n",
    "    #           'smsp__sass_thread_inst_executed_op_dmul_pred_on']\n",
    "    #tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    #tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP64 FLOPs\"})\n",
    "    #metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP64 FLOPs\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### FP32 FLOPs\n",
    "    metrics = ['smsp__sass_thread_inst_executed_op_fadd_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_ffma_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_fmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP32 FLOPs Avg\"})\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP32 FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### FP16 FLOPs\n",
    "    metrics = ['smsp__sass_thread_inst_executed_op_hadd_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_hfma_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_hmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP16 FLOPs Avg\"})\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP16 FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    #### TC FLOPs\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"] == \"sm__inst_executed_pipe_tensor_op_hmma\", selectkeys+[\"TC Time Avg\", \"Metric Value\"] ].copy()\n",
    "    tmpdf[\"Utilization\"] = 0.01 * tmpdf[\"Metric Value\"]\n",
    "    tmpdf[\"TC FLOPs Avg\"] = tc_peak_perf_flops * tmpdf[\"Utilization\"] * tmpdf[\"TC Time Avg\"]\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"TC FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    \n",
    "    ### Total FLOPs\n",
    "    metricdf[\"FLOPs Avg\"] = metricdf[\"FP32 FLOPs Avg\"] + metricdf[\"FP16 FLOPs Avg\"] + metricdf[\"TC FLOPs Avg\"] #+ metricdf[\"FP64 FLOPs\"]\n",
    "    \n",
    "    \n",
    "    ### FLOPs fractions\n",
    "    #metricdf[\"FP64 FLOPs Fraction\"] = metricdf[\"FP64 FLOPs\"]/metricdf[\"FLOPs\"]\n",
    "    metricdf[\"FP32 FLOPs Fraction Avg\"] = metricdf[\"FP32 FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    metricdf[\"FP16 FLOPs Fraction Avg\"] = metricdf[\"FP16 FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    metricdf[\"TC FLOPs Fraction Avg\"]   = metricdf[\"TC FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    \n",
    "    ####### Get number of bytes\n",
    "    \n",
    "    ### Shared transactions\n",
    "    #project out\n",
    "    shareddf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__data_pipe_lsu_wavefronts_mem_shared_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    shareddf = shareddf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Shared Transactions Avg\"})\n",
    "    #add to timings\n",
    "    metricdf = metricdf.merge(shareddf[selectkeys+[\"Shared Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    \n",
    "    ### L1 atomic transactions\n",
    "    # project out\n",
    "    metrics = ['l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom',\n",
    "               'l1tex__t_set_accesses_pipe_lsu_mem_global_op_red',\n",
    "               'l1tex__t_set_accesses_pipe_tex_mem_surface_op_atom',\n",
    "               'l1tex__t_set_accesses_pipe_tex_mem_surface_op_red']\n",
    "    atomicdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    # get reads and writes\n",
    "    atomicdf = atomicdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L1 Atomic Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(atomicdf[selectkeys+[\"L1 Atomic Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Local transactions \n",
    "    # project out\n",
    "    localdf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__t_sectors_pipe_lsu_mem_local_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    localdf = localdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Local Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(localdf[selectkeys+[\"Local Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Global transactions \n",
    "    # project out\n",
    "    globaldf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__t_sectors_pipe_lsu_mem_global_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    globaldf = globaldf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Global Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(globaldf[selectkeys+[\"Global Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### L1 Bytes\n",
    "    metricdf[\"L1 Transactions Avg\"] = (metricdf[\"Shared Transactions Avg\"] + metricdf[\"L1 Atomic Transactions Avg\"]\n",
    "                            + metricdf[\"Local Transactions Avg\"] + metricdf[\"Global Transactions Avg\"])\n",
    "    metricdf[\"L1 Bytes Avg\"] = metricdf[\"L1 Transactions Avg\"] * 32\n",
    "    \n",
    "    \n",
    "    ### L2 atomic & reduction\n",
    "    metricdf.loc[(metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_op\")) & (metricdf[\"Metric Type\"]==\"total\"), [\"Metric Value\"]] *= 2\n",
    "\n",
    "    \n",
    "    ### L2 transactions\n",
    "    # project out\n",
    "    l2df = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    l2df = l2df.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L2 Transactions Avg\"})\n",
    "    l2df[\"L2 Bytes Avg\"] = l2df[\"L2 Transactions Avg\"] * 32\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(l2df[selectkeys+[\"L2 Transactions Avg\", \"L2 Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### DRAM Bytes\n",
    "    # project out\n",
    "    dramdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"dram__sectors\") ].sort_values(selectkeys)\n",
    "    # get reads and writes\n",
    "    dramreadsdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram__sectors\") & (dramdf[\"Metric Type\"]==\"read\"), selectkeys+[\"Metric Value\"]]\n",
    "    dramwritesdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram__sectors\") & (dramdf[\"Metric Type\"]==\"write\"), selectkeys+[\"Metric Value\"]]\n",
    "    # combine\n",
    "    dramdf = dramwritesdf.merge(dramreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    dramdf[\"DRAM Transactions Avg\"] = dramdf[\"Metric Value_x\"] + dramdf[\"Metric Value_y\"]\n",
    "    dramdf[\"DRAM Bytes Avg\"] = dramdf[\"DRAM Transactions Avg\"] * 32\n",
    "    #print(dramdf[['Name', 'Metric Value_x', 'Metric Value_y']])\n",
    "    metricdf = metricdf.merge(dramdf[selectkeys+[\"DRAM Transactions Avg\", \"DRAM Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Host Memory Bytes\n",
    "    # project out\n",
    "    sysmemdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_aperture_sysmem_op\") ].sort_values(selectkeys)\n",
    "    # get reads and writes\n",
    "    sysmemreadsdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"lts__t_sectors_aperture_sysmem_op\") & (sysmemdf[\"Metric Type\"]==\"read\"), selectkeys+[\"Metric Value\"]]\n",
    "    sysmemwritesdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"lts__t_sectors_aperture_sysmem_op\") & (sysmemdf[\"Metric Type\"]==\"write\"), selectkeys+[\"Metric Value\"]]\n",
    "    # combine\n",
    "    sysmemdf = sysmemwritesdf.merge(sysmemreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    sysmemdf[\"SYSMEM Transactions Avg\"] = sysmemdf[\"Metric Value_x\"] + sysmemdf[\"Metric Value_y\"]\n",
    "    sysmemdf[\"SYSMEM Bytes Avg\"] = sysmemdf[\"SYSMEM Transactions Avg\"] * 32\n",
    "    #print(dramdf[['Name', 'Metric Value_x', 'Metric Value_y']])\n",
    "    metricdf = metricdf.merge(sysmemdf[selectkeys+[\"SYSMEM Transactions Avg\", \"SYSMEM Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ####### Clean up and return:\n",
    "    del metricdf[\"Metric Value\"]\n",
    "    del metricdf[\"Metric Name\"]\n",
    "    del metricdf[\"Metric Type\"]\n",
    "    #del metricdf[\"Invocations\"]\n",
    "    metricdf.drop_duplicates(keep = 'first', inplace = True)\n",
    "    \n",
    "\n",
    "    ### Get performance\n",
    "    metricdf[\"Performance GFlop/s\"]      = metricdf[\"FLOPs Avg\"]      / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"FP32 Performance GFlop/s\"] = metricdf[\"FP32 FLOPs Avg\"] / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"FP16 Performance GFlop/s\"] = metricdf[\"FP16 FLOPs Avg\"] / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"TC Performance GFlop/s\"]   = metricdf[\"TC FLOPs Avg\"]   / (metricdf[\"TC Time Avg\"]*10**9)\n",
    "\n",
    "    \n",
    "    ### Get AI\n",
    "    # L1\n",
    "    metricdf[\"L1 AI\"]        = metricdf[\"FLOPs Avg\"]      / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"FP32 L1 AI\"]   = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"FP16 L1 AI\"]   = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"TC L1 AI\"]     = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"L1 Bytes Avg\"]\n",
    "    # L2\n",
    "    metricdf[\"L2 AI\"]        = metricdf[\"FLOPs Avg\"]      / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"FP32 L2 AI\"]   = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"FP16 L2 AI\"]   = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"TC L2 AI\"]     = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"L2 Bytes Avg\"]\n",
    "    # DRAM\n",
    "    metricdf[\"DRAM AI\"]      = metricdf[\"FLOPs Avg\"]      / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"FP32 DRAM AI\"] = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"FP16 DRAM AI\"] = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"TC DRAM AI\"]   = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"DRAM Bytes Avg\"]\n",
    "    # SYSMEM\n",
    "    metricdf[\"SYSMEM AI\"]      = metricdf[\"FLOPs Avg\"]      / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"FP32 SYSMEM AI\"] = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"FP16 SYSMEM AI\"] = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"TC SYSMEM AI\"]   = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "\n",
    "    ### Cleanup\n",
    "    metricdf.sort_values(by=selectkeys).reset_index(drop=True, inplace=True)\n",
    "    #print(metricdf[['CUDA Time Avg', 'TC Time Avg']])\n",
    "    \n",
    "    return metricdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files\n",
    "files = []\n",
    "for datadir in datadirs:\n",
    "    files += [ os.path.join(datadir,x) for x in os.listdir(datadir) if ((os.path.splitext(x)[-1] == \".ncu-rep\"))]\n",
    "\n",
    "#recs\n",
    "records = []\n",
    "\n",
    "#build feature list:\n",
    "for path in files:\n",
    "    \n",
    "    #filename\n",
    "    file = os.path.basename(path)\n",
    "    \n",
    "    #path\n",
    "    path = os.path.dirname(path)\n",
    "    \n",
    "    #splitup\n",
    "    splt = file.split(\".\")\n",
    "    \n",
    "    prefix = \".\".join(splt[0:-1])\n",
    "    \n",
    "    #append to records\n",
    "    records.append({\"prefix\": prefix, \"file\": os.path.join(path, file)})\n",
    "\n",
    "#put in df\n",
    "recorddf = pd.DataFrame(records).sort_values([\"prefix\"])\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by those keys:\n",
    "sortkeys = [\"Network Name\", \\\n",
    "            \"Batch Size\", \"Pass\", \\\n",
    "            \"Precision\", \"Device\", \"Name\"]\n",
    "    \n",
    "#group by prefixes and files\n",
    "all_prefixes = set([x.split(\".pass\")[0] for x in recorddf[\"prefix\"]])\n",
    "all_passes = set([re.match(r'.*\\.pass_(.*?)\\.', x).groups()[0] for x in recorddf[\"prefix\"].unique()])\n",
    "\n",
    "#metrics\n",
    "df_profiles = []\n",
    "\n",
    "for pref in all_prefixes:\n",
    "    \n",
    "    #set empty lists\n",
    "    df_times = []\n",
    "    df_timeline = []\n",
    "    df_summary = []\n",
    "    \n",
    "    #print prefix\n",
    "    #print(pref)\n",
    "    \n",
    "    #loop over passes\n",
    "    df_times = []\n",
    "    df_metrics = []\n",
    "    for pas in all_passes:\n",
    "        \n",
    "        #project frame\n",
    "        files = recorddf.loc[recorddf[\"prefix\"].apply(lambda x: re.match(r'.*\\.pass_(.*?)\\.', x).groups()[0]) == pas, \"file\"].values\n",
    "        \n",
    "        #project the invididual files\n",
    "        metricfiles = [x for x in files if x.endswith(\".ncu-rep\")]\n",
    "        \n",
    "        for metricfile in metricfiles:\n",
    "            \n",
    "            #print the file\n",
    "            print(metricfile)\n",
    "            \n",
    "            #get the parameters from the filename\n",
    "            parameters = parse_filename_nsight(os.path.basename(metricfile))\n",
    "        \n",
    "            #metrics\n",
    "            metricdf = import_nsight_metric(metricfile, cuda_dir=cudadir)\n",
    "            for key in parameters:\n",
    "                metricdf[key] = parameters[key]\n",
    "        \n",
    "            #fuse read/write metrics together:\n",
    "            unique_metrics = metricdf[\"Metric Name\"].unique()\n",
    "            unique_metrics = set([x.split(\".\")[0].replace(\"_write\",\"\").replace(\"_read\",\"\").replace(\"_ld\",\"\").replace(\"_st\",\"\") for x in unique_metrics])\n",
    "            #add the metric type\n",
    "            metricdf[\"Metric Type\"] = \"total\"\n",
    "            #read\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_read\"), \"Metric Type\" ] = \"read\"\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_ld\"), \"Metric Type\" ] = \"read\"\n",
    "            #write\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_write\"), \"Metric Type\" ] = \"write\"\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_st\"), \"Metric Type\" ] = \"write\"\n",
    "            #rate\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\".per_second\"), \"Metric Type\" ] = \"rate\"\n",
    "        \n",
    "            for metric in unique_metrics:\n",
    "                metricdf.loc[ metricdf[ \"Metric Name\"].str.startswith(metric), \"Metric Name\" ] = metric\n",
    "\n",
    "            #append to DF:\n",
    "            df_metrics.append(metricdf)\n",
    "    \n",
    "    #concat the frames\n",
    "    metricdf = pd.concat(df_metrics).reset_index(drop=True)\n",
    "    \n",
    "    #compute the profile\n",
    "    profiledf = transpose_frame(metricdf)\n",
    "    df_profiles.append(profiledf)\n",
    "\n",
    "#concat everything\n",
    "profiledf = pd.concat(df_profiles).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum over all kernels\n",
    "combinedselectkeys = [\"Precision\", \"Network Name\", \"Batch Size\", \"Pass\"]\n",
    "\n",
    "#copy profiledf\n",
    "combineddf = profiledf.copy()\n",
    "\n",
    "#get the aggregated performance, including all kernels:\n",
    "#compute weights: multiply all measures by the number of invocations\n",
    "weighted = True\n",
    "if weighted:\n",
    "    #first, get all the names of metrics which need to be weighted\n",
    "    metrics = [x for x in combineddf.columns if \"Avg\" in x]\n",
    "    for metric in metrics:\n",
    "        combineddf[metric] *= combineddf[\"Invocations\"]\n",
    "\n",
    "#sum up\n",
    "combineddf = combineddf.groupby(by=combinedselectkeys).sum()#.reset_index()\n",
    "\n",
    "\n",
    "#the flop fractions need to be recomputed\n",
    "combineddf[\"FP32 FLOPs Fraction Avg\"] = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"FLOPs Avg\"]\n",
    "combineddf[\"FP16 FLOPs Fraction Avg\"] = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"FLOPs Avg\"]\n",
    "combineddf[\"TC FLOPs Fraction Avg\"]   = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"FLOPs Avg\"]\n",
    "\n",
    "### Get performance\n",
    "combineddf[\"Performance GFlop/s\"]      = combineddf[\"FLOPs Avg\"]      / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"FP32 Performance GFlop/s\"] = combineddf[\"FP32 FLOPs Avg\"] / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"FP16 Performance GFlop/s\"] = combineddf[\"FP16 FLOPs Avg\"] / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"TC Performance GFlop/s\"]   = combineddf[\"TC FLOPs Avg\"]   / (combineddf[\"TC Time Avg\"]*10**9)\n",
    "\n",
    "\n",
    "### Get AI\n",
    "# L1\n",
    "combineddf[\"L1 AI\"]        = combineddf[\"FLOPs Avg\"]      / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"FP32 L1 AI\"]   = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"FP16 L1 AI\"]   = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"TC L1 AI\"]     = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"L1 Bytes Avg\"]\n",
    "# L2\n",
    "combineddf[\"L2 AI\"]        = combineddf[\"FLOPs Avg\"]      / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"FP32 L2 AI\"]   = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"FP16 L2 AI\"]   = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"TC L2 AI\"]     = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"L2 Bytes Avg\"]\n",
    "# DRAM\n",
    "combineddf[\"DRAM AI\"]      = combineddf[\"FLOPs Avg\"]      / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"FP32 DRAM AI\"] = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"FP16 DRAM AI\"] = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"TC DRAM AI\"]   = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"DRAM Bytes Avg\"]\n",
    "\n",
    "combineddf.sort_values(by=combinedselectkeys).reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricdf.to_csv(\"./metrics.csv\")\n",
    "profiledf.to_csv(\"./profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
