{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "del sys.path[0]; del sys.path[0] # remove local utils.py\n",
    "sys.path.append(os.environ['HOME']+'/mlcomhpc/deepcam/src/deepCam')\n",
    "os.environ['PMI_NO_PREINITIALIZE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from attrdict import AttrDict\n",
    "from utils import parser\n",
    "from data import get_dataloaders, get_datashapes\n",
    "\n",
    "seed=42\n",
    "# fix random seed\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batchnorm_group_size=1, channels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], checkpoint=None, data_dir_prefix='/', gradient_accumulation_frequency=1, local_batch_size=1, logging_frequency=100, lr_schedule=None, lr_warmup_factor=1.0, lr_warmup_steps=0, max_epochs=30, max_inter_threads=4, model_prefix='model', optimizer='Adam', optimizer_betas=[0.9, 0.999], output_dir=None, resume_logging=False, run_tag=None, save_frequency=0, seed=333, start_lr=0.001, target_iou=0.82, valid_batch_size=2, wandb_certdir='/opt/certs', weight_decay=1e-06, wireup_method='nccl-openmpi')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pargs = parser.parse_arguments('')\n",
    "pargs.max_inter_threads=4\n",
    "pargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with  121216  samples.\n",
      "Initialized dataset with  15158  samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15158"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir=\"/scratch/snx3000/dealmeih/ds/mlperf/deepcam/All-Hist/\"\n",
    "device='cuda'\n",
    "comm_size=128\n",
    "comm_rank=0\n",
    "pargs.valid_batch_size=2\n",
    "train_loader, train_size, validation_loader, validation_size = get_dataloaders(pargs, root_dir, device, seed, comm_size, comm_rank)\n",
    "validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 2.06 s, total: 5.21 s\n",
      "Wall time: 8.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, torch.Size([1, 16, 768, 1152]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i, b in enumerate(validation_loader):\n",
    "    pass\n",
    "i+1, b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of output channels: 3\n",
      "Output stride: 16\n",
      "Number of Input Channels: 16\n"
     ]
    }
   ],
   "source": [
    "from architecture import deeplab_xception\n",
    "from utils import losses\n",
    "from driver import train_step, validate\n",
    "loss_pow = -0.125\n",
    "class_weights = [0.986267818390377**loss_pow, 0.0004578708870701058**loss_pow, 0.01327431072255291**loss_pow]\n",
    "\n",
    "class MockLogger:\n",
    "    def log_start(self, *args, **kvargs): pass\n",
    "    def log_end(self, *args, **kvargs): pass\n",
    "    def log_event(self, *args, **kvargs): print(*args, kvargs)\n",
    "\n",
    "criterion = losses.CELoss(class_weights).to(device)\n",
    "\n",
    "net = deeplab_xception.DeepLabv3_plus(n_input = 16,\n",
    "                                      n_classes = 3, \n",
    "                                      os=16, pretrained=False, \n",
    "                                      rank = 0,\n",
    "                                      process_group = None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'eval_accuracy', 'value': 0.13863393639316077, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "{'key': 'eval_loss', 'value': 30375641.277310923, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "CPU times: user 10.4 s, sys: 5.42 s, total: 15.8 s\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "validate(pargs, comm_size, comm_rank,\n",
    "         device, 0, 0,\n",
    "         net, criterion, validation_loader,\n",
    "         MockLogger())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_iter = iter(validation_loader)\n",
    "import time\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'eval_accuracy', 'value': 0.13863393639316077, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "{'key': 'eval_loss', 'value': 30375641.277310923, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "CPU times: user 10.5 s, sys: 5.11 s, total: 15.6 s\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "validate(pargs, comm_size, comm_rank,\n",
    "         device, 0, 0,\n",
    "         net, criterion, validation_iter,\n",
    "         MockLogger())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test original 'validate' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# base stuff\n",
    "import os\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "# custom stuff\n",
    "from utils import metric\n",
    "\n",
    "\n",
    "def orig_validate(pargs, comm_rank, comm_size,\n",
    "             device, step, epoch, \n",
    "             net, criterion, validation_loader, \n",
    "             logger):\n",
    "    \n",
    "    logger.log_start(key = \"eval_start\", metadata = {'epoch_num': epoch+1})\n",
    "\n",
    "    #eval\n",
    "    net.eval()\n",
    "\n",
    "    count_sum_val = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "    loss_sum_val = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "    iou_sum_val = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "\n",
    "    # disable gradients\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # iterate over validation sample\n",
    "        step_val = 0\n",
    "        # only print once per eval at most\n",
    "        for inputs_val, label_val, filename_val in validation_loader:\n",
    "\n",
    "            #send to device\n",
    "            inputs_val = inputs_val.to(device)\n",
    "            label_val = label_val.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs_val = net.forward(inputs_val)\n",
    "            loss_val = criterion(outputs_val, label_val)\n",
    "\n",
    "            # accumulate loss\n",
    "            loss_sum_val += loss_val\n",
    "        \n",
    "            #increase counter\n",
    "            count_sum_val += 1.\n",
    "        \n",
    "            # Compute score\n",
    "            predictions_val = torch.argmax(torch.softmax(outputs_val, 1), 1)\n",
    "            iou_val = metric.compute_score(predictions_val, label_val, num_classes=3)\n",
    "            iou_sum_val += iou_val\n",
    "        \n",
    "            #increase eval step counter\n",
    "            step_val += 1\n",
    "                \n",
    "        # average the validation loss\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(count_sum_val, op=dist.ReduceOp.SUM, async_op=False)\n",
    "            dist.reduce(loss_sum_val, dst=0, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(iou_sum_val, op=dist.ReduceOp.SUM, async_op=False)\n",
    "        loss_avg_val = loss_sum_val.item() / count_sum_val.item()\n",
    "        iou_avg_val = iou_sum_val.item() / count_sum_val.item()\n",
    "\n",
    "    # print results\n",
    "    logger.log_event(key = \"eval_accuracy\", value = iou_avg_val, metadata = {'epoch_num': epoch+1, 'step_num': step})\n",
    "    logger.log_event(key = \"eval_loss\", value = loss_avg_val, metadata = {'epoch_num': epoch+1, 'step_num': step})\n",
    "\n",
    "    stop_training = False\n",
    "    if (iou_avg_val >= pargs.target_iou):\n",
    "        logger.log_event(key = \"target_accuracy_reached\", value = pargs.target_iou, metadata = {'epoch_num': epoch+1, 'step_num': step})\n",
    "        stop_training = True\n",
    "\n",
    "    # set to train\n",
    "    net.train()\n",
    "\n",
    "    logger.log_end(key = \"eval_stop\", metadata = {'epoch_num': epoch+1})\n",
    "    \n",
    "    return stop_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with  121216  samples.\n",
      "Initialized dataset with  15158  samples.\n"
     ]
    }
   ],
   "source": [
    "pargs.valid_batch_size=1\n",
    "train_loader, train_size, validation_loader, validation_size = get_dataloaders(pargs, root_dir, device, seed, comm_size, comm_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'eval_accuracy', 'value': 0.13863393639316077, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "{'key': 'eval_loss', 'value': 30375630.521008402, 'metadata': {'epoch_num': 1, 'step_num': 0}}\n",
      "CPU times: user 13 s, sys: 4.43 s, total: 17.5 s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "orig_validate(pargs, comm_size, comm_rank,\n",
    "         device, 0, 0,\n",
    "         net, criterion, validation_loader,\n",
    "         MockLogger())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcam",
   "language": "python",
   "name": "dcam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
